{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MuRIL_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Purav0788/MuRIL3/blob/master/MuRIL_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmQuuzzJmG2g",
        "outputId": "5e8bcdd7-5371-432f-e88b-f465aafe2649"
      },
      "source": [
        "!pip install gpustat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gpustat in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat) (5.4.8)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from gpustat) (1.15.0)\n",
            "Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.7/dist-packages (from gpustat) (1.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjrW4eMJmRW7",
        "outputId": "4829a327-0aa6-4176-f49e-c1809afbff70"
      },
      "source": [
        "!gpustat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[37m39be2defab1b       \u001b[m  Tue Nov  9 09:29:33 2021  \u001b[1m\u001b[30m460.32.03\u001b[m\n",
            "\u001b[36m[0]\u001b[m \u001b[34mTesla K80       \u001b[m |\u001b[1m\u001b[31m 70'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 2222\u001b[m / \u001b[33m11441\u001b[m MB |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQEJ8IXkmTes",
        "outputId": "6810711a-2e05-4eeb-f96a-a72de9244c24"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hifvghb-mfeg",
        "outputId": "a04c3d41-fec3-4c54-f563-8647e9f6d6f4"
      },
      "source": [
        "!pwd\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/MuRIL')\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/MuRIL\n",
            "/content/drive/My Drive/MuRIL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjNwvRhbmfin",
        "outputId": "443ed1f5-2a19-45d7-c77e-adefc57b1250"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.7/dist-packages (0.14.9)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwJ7igw4mfgt",
        "outputId": "303b0578-0c62-4618-853f-8b9d1e744c40"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import bert\n",
        "from tensorflow.keras.models import  Model\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import namedtuple\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from bert import bert_tokenization\n",
        "print(\"TensorFlow Version:\",tf.__version__)\n",
        "print(\"Hub version: \",hub.__version__)\n",
        "from keras import backend as K\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.6.0\n",
            "Hub version:  0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QixDBKKoESF",
        "outputId": "79274dbb-6722-4b27-817b-872a8a6ac188"
      },
      "source": [
        "\n",
        "# Load train and val datasets\n",
        "# df_full_train = pd.read_csv('gj.csv', sep = \",\", engine='c', error_bad_lines=False)\n",
        "df_full_train = pd.read_csv('hi.tsv', sep = \"\\t\", engine='python', error_bad_lines=False)\n",
        "df_full_train = df_full_train[(df_full_train.label != 'bioche')&(df_full_train.label !=  'com_tech')&(df_full_train.label !=  'cse')&(df_full_train.label !=  'math')&(df_full_train.label != 'mgmt')]\n",
        "df_train, df_val = train_test_split(df_full_train, test_size=0.2)\n",
        "# df_train, df_val = train_test_split(df_full_train, test_size=0.2)\n",
        "# df_val = pd.read_csv('malayalam_dev.tsv', sep = \"\\t\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Skipping line 2937: '\t' expected after '\"'\n",
            "Skipping line 3220: '\t' expected after '\"'\n",
            "Skipping line 4170: '\t' expected after '\"'\n",
            "Skipping line 8480: '\t' expected after '\"'\n",
            "Skipping line 12906: '\t' expected after '\"'\n",
            "Skipping line 17540: '\t' expected after '\"'\n",
            "Skipping line 19442: '\t' expected after '\"'\n",
            "Skipping line 23751: '\t' expected after '\"'\n",
            "Skipping line 25806: '\t' expected after '\"'\n",
            "Skipping line 31271: '\t' expected after '\"'\n",
            "Skipping line 33531: '\t' expected after '\"'\n",
            "Skipping line 34046: '\t' expected after '\"'\n",
            "Skipping line 34723: '\t' expected after '\"'\n",
            "Skipping line 35578: '\t' expected after '\"'\n",
            "Skipping line 35816: '\t' expected after '\"'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEXVtLY4zKXA",
        "outputId": "ac9b7f5c-6b76-43d9-f4ba-862f94952149"
      },
      "source": [
        "# Columns\n",
        "df_train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'label'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW-PO8F8p4HA",
        "outputId": "cb66f3f1-5160-4105-e8db-9b5e2bf46997"
      },
      "source": [
        "# Prepare input text and one hot encoded labels for train and validation sets\n",
        "\n",
        "# unique_labels = list(np.unique(df_train[\"label\"]))\n",
        "df_train.dropna(inplace = True)\n",
        "# print(df_train[\"label\"].unique())\n",
        "unique_labels = list(np.unique(df_train.iloc[:,1]))\n",
        "\n",
        "train_x = df_train.iloc[:,0].values\n",
        "train_y = df_train.iloc[:,1].values\n",
        "\n",
        "print(train_x)\n",
        "# print(train_y)\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "train_y = le.fit_transform(train_y)\n",
        "train_y = tf.keras.utils.to_categorical(train_y, num_classes=len(unique_labels), dtype='float32')\n",
        "\n",
        "val_x = df_val.iloc[:,0].values\n",
        "val_y = df_val.iloc[:,1].values\n",
        "\n",
        "val_y = le.fit_transform(val_y)\n",
        "val_y = tf.keras.utils.to_categorical(val_y, num_classes=len(unique_labels), dtype='float32')\n",
        "\n",
        "\n",
        "# print(\"number of unique labels\", len(unique_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['इसशलए , 1 99 0 के उत्तराधासेआर् भी आर् तक कई ऐसी कं पननयां रही हैंजर्न्होंनेव्यािसानयक रूप सेउपलबध ईंधन कोशिकाओंको बनानेकी कोशिि की है ।'\n",
            " 'कार्बन एक प्रमुख चक्र है जो मानव गतिविधियों से प्रभावित होता है , और वातावरण में कार्बन डाइऑक्साइड तापमान बनाए रखने , तापमान बनाए रखने का एक कारण है और यह ऐटमौसफ़ेयर  में इसकी मात्रा द्वारा केवल 0.03 % बनता है ।'\n",
            " 'तो , यह कुछ ऐसा है र्ो आप यहांदेखतेहैं ।' ...\n",
            " 'इसे विराट ई खालसा कहा जाता है , यह वास्तव में एक सिख संग्रहालय था और इसे वास्तुकार मोशे सफी द्वारा डिजाइन  किया गया था ।'\n",
            " 'वैज्ञानिक अनुसंधान के उत्पाद किसी विशेष समय और स्थान पर विशेष एजेंटों द्वारा बनाये जाते हैं ।'\n",
            " 'यह एक और स्लाइड  है जो उत्तराखंड में लकड़ी की नक्काशी के बारे में बात करती है ।']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUD20x5Oqzgp",
        "outputId": "9572573f-99a2-45c2-b8cd-ac190105c99c"
      },
      "source": [
        "# Check unique labels\n",
        "unique_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['other', 'phy']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEHX4WgmnIkM"
      },
      "source": [
        "# Function to create input_ids\n",
        "def get_ids(tokens, tokenizer, max_seq_length):\n",
        "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens,)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids\n",
        "\n",
        "# Function to create attention masks\n",
        "def get_masks(tokens, max_seq_length):\n",
        "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "# Function to create segment ids\n",
        "def get_segments(tokens, max_seq_length):\n",
        "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "# Function to create input_ids, attention_masks, segment_ids for sample\n",
        "def create_single_input(sentence,MAX_LEN, MAX_SEQ_LEN):\n",
        "  \n",
        "  stokens = tokenizer.tokenize(sentence)\n",
        "  \n",
        "  stokens = stokens[:MAX_LEN]\n",
        "  \n",
        "  stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
        " \n",
        "  ids = get_ids(stokens, tokenizer, MAX_SEQ_LEN)\n",
        "  masks = get_masks(stokens, MAX_SEQ_LEN)\n",
        "  segments = get_segments(stokens, MAX_SEQ_LEN)\n",
        "\n",
        "  return ids,masks,segments\n",
        "\n",
        "def create_input_array(sentences, MAX_SEQ_LEN):\n",
        "\n",
        "  input_ids, input_masks, input_segments = [], [], []\n",
        "\n",
        "  for sentence in tqdm(sentences,position=0, leave=True):\n",
        "  \n",
        "    ids,masks,segments=create_single_input(sentence,MAX_SEQ_LEN-2, MAX_SEQ_LEN)\n",
        "\n",
        "    input_ids.append(ids)\n",
        "    input_masks.append(masks)\n",
        "    input_segments.append(segments)\n",
        "\n",
        "  return [np.asarray(input_ids, dtype=np.int32), \n",
        "            np.asarray(input_masks, dtype=np.int32), \n",
        "            np.asarray(input_segments, dtype=np.int32)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8AmiWuknTKL"
      },
      "source": [
        "# MuRIL model layer\n",
        "muril_layer = hub.KerasLayer(\"https://tfhub.dev/google/MuRIL/1\", trainable=False)\n",
        "\n",
        "# Create tokenizer\n",
        "vocab_file = muril_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = muril_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = bert_tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDqjXUqturNk",
        "outputId": "d92ec0cb-a838-4dad-d57f-04fad7d01919"
      },
      "source": [
        "# Create input_ids, attention_masks, segment_ids for training and validation sets with max_seq_len as 128\n",
        "max_seq_len = 128\n",
        "train_x = create_input_array(train_x, max_seq_len)\n",
        "val_x = create_input_array(val_x, max_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10103/10103 [00:04<00:00, 2189.70it/s]\n",
            "100%|██████████| 2526/2526 [00:01<00:00, 2271.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaCe5lb9NyiR"
      },
      "source": [
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "  def on_train_batch_end(self, batch, logs = None):\n",
        "    print(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTuaOWdIwSOv"
      },
      "source": [
        "my_callbacks = [\n",
        "    # tf.keras.callbacks.EarlyStopping(patience=2),\n",
        "    # tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtImk-2eqn4a"
      },
      "source": [
        "# Define model function - compile and fit\n",
        "def model_fit(train_x, train_y, val_x, val_y, max_seq_length, num_epochs, muril_layer):\n",
        "\n",
        "  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "  segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                    name=\"segment_ids\")\n",
        "  \n",
        "  outputs = muril_layer(dict(input_word_ids = input_word_ids, input_mask = input_mask, input_type_ids = segment_ids))\n",
        "\n",
        "  # my_outputs = K.print_tensor(outputs, message =\"muril Layer encodings\")\n",
        "  print(outputs[\"sequence_output\"].shape)\n",
        "  print(outputs[\"pooled_output\"].shape)\n",
        "  # model.summary()\n",
        "  x = tf.keras.layers.Dropout(0.2)(outputs[\"pooled_output\"]) # take pooled output layer\n",
        "  # print(x)\n",
        "  final_output = tf.keras.layers.Dense(len(unique_labels), activation=\"softmax\", name=\"dense_output\")(x)\n",
        "  my_final_output = K.print_tensor(final_output)\n",
        "  # tf.print(final_output, output_stream = sys.stderr)\n",
        "  model = tf.keras.models.Model(\n",
        "      inputs=[input_word_ids, input_mask, segment_ids], outputs=my_final_output)\n",
        "  opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=True, name=\"SGD\")\n",
        "  opt = tfa.optimizers.Lookahead(opt)\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['f1_score'])\n",
        "  K.set_value(model.optimizer.learning_rate, 0.001)\n",
        "  model.summary()\n",
        "  model.fit(train_x, train_y, epochs = num_epochs, batch_size = 32, validation_data = (val_x, val_y), shuffle = True, callbacks = my_callbacks)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alZ5cnpP-66X"
      },
      "source": [
        "# Define model function - compile and fit\n",
        "def model_fit(train_x, train_y, val_x, val_y, max_seq_length, num_epochs, muril_layer):\n",
        "\n",
        "  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "  segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                    name=\"segment_ids\")\n",
        "  \n",
        "  outputs = muril_layer(dict(input_word_ids = input_word_ids, input_mask = input_mask, input_type_ids = segment_ids))\n",
        "\n",
        "  x = tf.keras.layers.Dropout(0.2)(outputs[\"pooled_output\"]) # take pooled output layer\n",
        "  final_output = tf.keras.layers.Dense(len(unique_labels), activation=\"softmax\", name=\"dense_output\")(x)\n",
        "\n",
        "  model = tf.keras.models.Model(\n",
        "      inputs=[input_word_ids, input_mask, segment_ids], outputs=final_output)\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "  \n",
        "  # Define the Keras TensorBoard callback.\n",
        "  logdir=\"logs/fit/metrics\"\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "  history = model.fit(train_x, train_y, epochs = num_epochs, batch_size = 32, validation_data = (val_x, val_y), shuffle = True, callbacks=[tensorboard_callback])\n",
        "\n",
        "  return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfQ_Jv6sulcq",
        "outputId": "099b260a-62b6-4310-ce5d-f47c06b16267"
      },
      "source": [
        "# Set number of epochs\n",
        "num_epochs = 1\n",
        "\n",
        "# Get the model object\n",
        "model = model_fit(train_x, train_y, val_x, val_y, max_seq_len, num_epochs, muril_layer)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "316/316 [==============================] - 268s 813ms/step - loss: 0.6902 - accuracy: 0.5394 - val_loss: 0.6889 - val_accuracy: 0.5400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "E8Y7dCzfrDJT",
        "outputId": "d3b88c39-7513-4940-bb92-8c25b6988401"
      },
      "source": [
        "# Make predictions\n",
        "preds = model.predict(val_x)\n",
        "print(preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-56146baab98f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'predict'"
          ]
        }
      ]
    }
  ]
}
